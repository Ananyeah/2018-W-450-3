{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install folium --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "mongo_client = MongoClient('this-mongo.cc', 27016)\n",
    "database_reference = mongo_client.twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_reference = database_reference.instructor_test_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_reference.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Aggregation Pipeline\n",
    "\n",
    "A call to the aggregation framework defines a pipeline (figure 6.1), the **aggregation pipeline**, where the output from each step in the pipeline provides input to the next step. Each step executes a single operation on the input documents to transform the input and generate output documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.evernote.com/l/AAGxerRxKLZNFrjqxlYK2HPz1R11tr95FFkB/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Aggregation Pipeline Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `$project` // Specify fields to be placed in the output document (projected).\n",
    "- `$match` // Select documents to be processed, similar to find().\n",
    "- `$limit` // Limit the number of documents to be passed to the next step.\n",
    "- `$skip` // Skip a specified number of documents.\n",
    "- `$unwind` // Expand an array, generating one output document for each array entry.\n",
    "- `$group` // Group documents by a specified key.\n",
    "- `$sort` // Sort documents.\n",
    "- `$geoNear` // Select documents near a geospatial location.\n",
    "- `$out` // Write the results of the pipeline to a collection (new in v2.6).\n",
    "- `$redact` // Control access to certain data (new in v2.6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dictionary_to_datestring(x):\n",
    "    month = x['month']\n",
    "    day = x['day']\n",
    "    year = x['year']\n",
    "    return \"{}-{}-{}\".format(month, day, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cursor = collection_reference.aggregate([\n",
    "    date_to_id,\n",
    "    group_by_date\n",
    "])\n",
    "\n",
    "daily_tweets = pd.DataFrame(list(cursor))\n",
    "\n",
    "datestrings = daily_tweets['_id'].apply(dictionary_to_datestring)\n",
    "daily_tweets['date'] = pd.to_datetime(datestrings)\n",
    "\n",
    "daily_tweets.drop('_id', axis=1, inplace=True)\n",
    "daily_tweets.sort_values('date', inplace=True)\n",
    "daily_tweets.set_index('date', inplace=True)\n",
    "daily_tweets.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nonnull_geo = {'geo' : {'$ne' : None}}\n",
    "just_geo = {'geo' : 1}\n",
    "\n",
    "cursor = collection_reference.find(nonnull_geo, just_geo)\n",
    "cursor.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_tweets = pd.DataFrame(list(cursor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_geo_from_tweets(tweets):\n",
    "    geo = pd.DataFrame(list(tweets['geo'].values))\n",
    "    return geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = parse_geo_from_tweets(geo_tweets)\n",
    "geo.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "starting_loc = [34.0689, -118.4452]\n",
    "la_map = folium.Map(location=starting_loc, zoom_start=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for loc in geo.coordinates.values:\n",
    "    folium.Marker(loc).add_to(la_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
